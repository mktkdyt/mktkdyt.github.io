<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mktkdyt</title>
    <link>https://mktkdyt.github.io/</link>
    <description>Recent content on mktkdyt</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Thu, 14 Jan 2021 17:24:23 +0900</lastBuildDate><atom:link href="https://mktkdyt.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI をアプリに組み込む</title>
      <link>https://mktkdyt.github.io/post/machine_learning/ai%E3%82%92%E3%82%A2%E3%83%97%E3%83%AA%E3%81%AB%E7%B5%84%E3%81%BF%E8%BE%BC%E3%82%80/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/machine_learning/ai%E3%82%92%E3%82%A2%E3%83%97%E3%83%AA%E3%81%AB%E7%B5%84%E3%81%BF%E8%BE%BC%E3%82%80/</guid>
      <description>AI をアプリに組み込む シェルティー判定AIを作成する で作成したシェルティー判定 AI を Flask に組み込んでみます。
構成 Vagrant で構築した ubuntu 上で実施しました。 IP は 192.168.33.31 です。
~/python/api├─app.py├─ai.py├─model : 事前に作成したモデル│ ├─model_predict.json│ └─model_predict.hdf5├─static│ ├─favicon.ico : ファビコン（任意）│ └─style.css : スタイルシート├─templates : 画面テンプレート│ └─index.html├─images : アップロードされた画像を格納するディレクトリ└─uwsgi.ini : uWSGI の設定ファイルイメージ アプリケーション配備先を用意する $ mkdir -p ~/python/api $ cd ~/python/api $ python3 -m venv api $ source api/bin/activate # ai の実行に必要なライブラリをインストールする $ pip install werkzeug $ pip install numpy==1.</description>
    </item>
    
    <item>
      <title>Ajax の CSRF 対策</title>
      <link>https://mktkdyt.github.io/post/asp_dot_net/ajax%E3%81%AEcsrf%E5%AF%BE%E7%AD%96/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/asp_dot_net/ajax%E3%81%AEcsrf%E5%AF%BE%E7%AD%96/</guid>
      <description>Ajax の CSRF 対策 SPAで非同期通信を多用すると思います。その際に、非同期通信の場合のCSRF対策について調査ました。
通常の同期処理（ページ遷移）の場合 ASP.NET MVCではCSRF対策が超簡単です。
ViewのFormの中でRazorの@Html.AntiForgeryToken()を呼ぶだけでトークンを埋め込むことが出来ます。
トークンを検証するにはControllerでActionMethodの属性にValidationAntiForgeryTokneを指定するだけです。
View
@using (Html.BeginForm()){ @Html.AntiForgeryToken() // 略 } Controller
[ValidationAntiForgeryToken] [HttpPost] public ActionResult Create(ViewModel model){ // 略 } ところが、非同期処理（Ajax）の場合は少々工夫が必要になります。
非同期処理（Ajax）の場合 Razorでクッキーのトークンとフォームのトークンを発行する関数を作成します。
作成した関数を呼び、hidden値に設定し、POST時にヘッダに付加してリクエストを送信します。
View
&amp;lt;script&amp;gt; @functions{ public string GenerateRequestVerificationToken() { string cookieToken, formToken; AntiForgery.GetTokens(null, out cookieToken, out formToken); return cookieToken + &amp;#34;:&amp;#34; + formToken; } } &amp;lt;/script&amp;gt; &amp;lt;input type=&amp;#34;hidden&amp;#34; id=&amp;#34;requestValificationToken&amp;#34; value=&amp;#34;@GenerateRequestValificationToken()&amp;#34; /&amp;gt; JS
$.ajax({ url: http://test/Create,  type: &amp;#34;POST&amp;#34;, dataType: &amp;#34;json&amp;#34;, data: { data: hoge }, headers: { &amp;#39;RequestVerificationToken&amp;#39;: $(&amp;#39;#requestVerificationToken&amp;#39;).</description>
    </item>
    
    <item>
      <title>ASP.NET のモジュールを Jenkins で発行する</title>
      <link>https://mktkdyt.github.io/post/asp_dot_net/asp.net%E3%81%AE%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB%E3%82%92jenkins%E3%81%A7%E7%99%BA%E8%A1%8C%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/asp_dot_net/asp.net%E3%81%AE%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB%E3%82%92jenkins%E3%81%A7%E7%99%BA%E8%A1%8C%E3%81%99%E3%82%8B/</guid>
      <description>ASP.NET のモジュールを Jenkins で発行する デプロイモジュールを発行するために
msbuild target.sln /p:VisualStudioVersion=14.0 /p:DeployOnBuild=true /p:Configuration=targetStaging /p:PublishProfile=targetProfile をjenkinsのジョブに登録し、実行すると以下のエラーが発生。
C:\ProgramFiles (x86)\MSBuild\Microsoft\VisualStudio\v14.0\Web\Transform\Microsoft.Web.Publishing.AspNetCompileMerge.targets(132,5): error :  Can&amp;#39;t find the valid AspnetMergePath [C:\Jenkins\workspace\Common_Build\Apps\Pajdis.CommonAndPortal\Pajdis.CommonAndPortal\Pajdis.CommonAndPortal.csproj] なにこれ。VisualStudioで発行するときに見たこと無いぞ。 とりあえずコマンドにAspnetMergePathを明示すれば動くだろ。
msbuild target.sln /p:VisualStudioVersion=14.0 /p:DeployOnBuild=true /p:Configuration=targetStaging /p:PublishProfile=targetProfile /p:AspnetMergePath=&amp;#34;C:\Program Files (x86)\Microsoft SDKs\Windows\v8.1A\bin\NETFX 4.5.1 Tools\&amp;#34; よっしゃ実行だ！
MSBUILD : error MSB1008: 1 つのプロジェクトのみを指定できます。 なん。。だと。。。。動かない。。。
よくよく見ると
Path To MSBuild.exe: msbuild.exe Executing the command cmd.exe /C &amp;#34; msbuild.exe /p:VisualStudioVersion=14.0 /p:DeployOnBuild=true /p:Configuration=DebugPajdis /p:PublishProfile=DebugPajdis &amp;#34;\p:AspnetMergePath=C:\Program Files (x86)\Microsoft SDKs\Windows\v8.1A\bin\NETFX 4.5.1 Tools&amp;#34;&amp;#34; Apps\Pajdis.CommonAndPortal\Pajdis.CommonAndPortal.sln &amp;#34; &amp;amp;&amp;amp; exit %%ERRORLEVEL%%from C:\Jenkins\workspace\Common_Build [Common_Build] $ cmd.</description>
    </item>
    
    <item>
      <title>AutoMapper を導入する</title>
      <link>https://mktkdyt.github.io/post/asp_dot_net/automapper%E3%82%92%E5%B0%8E%E5%85%A5%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/asp_dot_net/automapper%E3%82%92%E5%B0%8E%E5%85%A5%E3%81%99%E3%82%8B/</guid>
      <description>AutoMapper を導入する AutoMapperって？ オブジェクトの詰め替えをしてくれるツール。 マッパーを使うことでオブジェクトの詰め替えをその都度記述する必要がなくなるのでコーディングの作業量を減らすことが出来ます。 また、オブジェクト間のプロパティの対応関係を局所化することが出来るので、修正箇所が限定されます。
AutoMapperの取得 NuGetからAutoMapperを取得
AutoMapperConfigの作成 using AutoMapper; using Terdis.MasterInfoManagement.Service.DataTransferObject; using Terdis.Map.Application.Web.Dto; namespace Terdis.Map.Application.Web { public class AutoMapperConfig { public static void RegisterAutoMappings() { Mapper.Initialize(cfg =&amp;gt; { cfg.CreateMap&amp;lt;MasterInfoDto, DocumentTypeDto&amp;gt;() .ForMember(d =&amp;gt; d.Id, o =&amp;gt; o.MapFrom(s =&amp;gt; s.Name)) .ForMember(d =&amp;gt; d.Title, o =&amp;gt; o.MapFrom(s =&amp;gt; s.Code)); }); } } } Global.asaxへの登録 namespace Terdis.Map.Application.Web { public class Global : HttpApplication { void Application_Start(object sender, EventArgs e) { AutoMapperConfig.RegisterAutoMappings(); } } } ServiceでMappingを行う using System.</description>
    </item>
    
    <item>
      <title>Docker インストール手順</title>
      <link>https://mktkdyt.github.io/post/performance_evaluation/docker%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E6%89%8B%E9%A0%86/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/performance_evaluation/docker%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E6%89%8B%E9%A0%86/</guid>
      <description>Docker インストール手順  Docker インストール手順  Docker Desktop For Windows  Hyper-V 有効化 インストーラー取得 インストーラー実行 動作確認   Docker Compose  インストール 動作確認      Docker Desktop For Windows Hyper-V 有効化 コントロール パネル\すべてのコントロール パネル項目\プログラムと機能\Windowsの機能の有効化または無効化 で Hyper-V を有効にする。
インストーラー取得 https://hub.docker.com/editions/community/docker-ce-desktop-windows/ から Docker Desktop for Windows をダウンロードする。
インストーラー実行 インストーラーを実行し Docker を使えるようにする。
動作確認 &amp;gt; docker --version Docker version 19.03.8, build afacb8b &amp;gt; docker pull nginx &amp;gt; docker run -d -p 8080:80 --name webserver nginx Docker Compose インストール   Powershell を 管理者権限 で起動する</description>
    </item>
    
    <item>
      <title>Elasticsearch を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/elasticsearch%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/elasticsearch%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>Elasticsearch を構築する ローカルで Elasticsearch を構築しました。 Elasticsearch 用に 3台，Kibana 用に 1台 VM を立てました。
VM 作成 Vagrantfile を作成して vagrant up します。
# Elasticsearch ノード数 es_cnt = 3 cnt = 4 Vagrant.configure(&amp;#34;2&amp;#34;) do |config| config.vm.box = &amp;#34;ubuntu/bionic64&amp;#34; config.vm.synced_folder &amp;#34;./share&amp;#34;, &amp;#34;/home/vagrant/share&amp;#34;, owner: &amp;#34;vagrant&amp;#34;, group: &amp;#34;vagrant&amp;#34; #--- Elasticsearch 構築 ---# (1..es_cnt).each do |i| config.vm.define &amp;#34;es#{i}&amp;#34; do | es | es.disksize.size = &amp;#39;50GB&amp;#39; es.vm.provider &amp;#34;virtualbox&amp;#34; do |vb| vb.memory = 8192 end es.vm.hostname = &amp;#34;es#{i}&amp;#34; es.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.</description>
    </item>
    
    <item>
      <title>JMeter Tips</title>
      <link>https://mktkdyt.github.io/post/performance_evaluation/jmetertips/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/performance_evaluation/jmetertips/</guid>
      <description>JMeter Tips Grafana で JMeter のメトリクスを表示する  JMeter シナリオに Backend Listener を追加することで JMeter -&amp;gt; InfluxDB -&amp;gt; Grafana という流れで Grafana で JMeter メトリクスをリアルタイムで可視化出来る。 Grafana で JMeter のメトリクスを描画するには InfluxDB にデータを送信するように JMeter シナリオに Backend Listener を追加する。  テスト計画を右クリックし，追加\リスナー\Backend Listener を選択する。 Backend Listener implemantation で org.apache.jmeter.visualizers.backend.influxdb.influxdbBackendListenerClient を選択する。    項目 設定     influxdbUrl http://127.0.0.1:8086/write?db=jmeter   summaryOnly true   application webeoc   measurement jmeter       Grafana でトランザクションごとにグラフを描画出来るように HTTP リクエストの名前を適宜設定する。  1シナリオで複数のシナリオを実行する  テスト計画に複数のスレッドグループを追加し，スレッドグループを別々に実行 のチェックを外す。  Run Thread Groups consecutively の誤訳が スレッドグループを別々に実行 となっている。 正しくはスレッドグループを連続で実行。   例：1シナリオで複数ユーザによる登録，複数ユーザによる画面リロードを同時実行する。  パラメータの受け渡し  正規表現抽出を HTTPリクエスト に追加し正規表現で抽出した値を変数に格納し別の HTTPリクエスト で変数を参照する。 例：CSRF値  一定間隔でリクエストを送信する  ループコントローラに定数タイマを追加すると配下の各リクエストでタイマが作動してしまう。 ループコントローラの先頭のリクエストの下に定数タイマを追加することで1ループあたり1回だけタイマが作動し一定間隔でリクエストを送信出来る。 例：一定間隔で画面更新を行う。  一定間隔でリクエストを複数回送信する  1 スレッドかつ 1 ループで同じ処理を複数回実施したい場合はループコントローラの中にループコントローラを置き下層のループコントローラに HTTP リクエストを追加する。 複数スレッドにする場合はスレッドグループを新たに作成し、スレッド数を適宜設定し、ループコントローラを追加する。 例：一定間隔でA機能のリクエストを2回，B機能のリクエストを4回送信する。  スレッドグループ共通化  スレッドグループに処理をまとめ別のスレッドグループからモジュールコントローラで呼び出す。 例：登録処理のスレッドグループと，画面更新処理のスレッドグループで共通してログイン処理を呼び出す。  スレッドグループの起動遅延  スレッドグループに「起動遅延」という設定があるが正常に動作しない場合がある。 スレッドグループに Flow Control Action を追加し Duration を設定することで対応出来る。  Flow Control Action の下に Syncronizing Timer を追加する。   特定のスレッドグループのみ起動遅延させるためには スレッドグループを別々に実行 のチェックを外す。 例：複数ユーザによるログイン処理を実行している間に登録処理を遅延実行する。  リスナー設定  シンプルデータライタ以外のリスナーは無効にする。 シンプルデータライタで Configure をクリックすると出力の設定が出来る。  Save As XML でXML形式で出力出来る。デフォルトはCSV。 Save Response Data でレスポンスを保存出来る。   シンプルデータライタの出力を読み込み，JMeter クライアントでグラフを描画する。 出力先は Log\_${_time(YMDHMS)}\result${__time(YMDHMS)}.</description>
    </item>
    
    <item>
      <title>JMeter インストール手順</title>
      <link>https://mktkdyt.github.io/post/performance_evaluation/jmeter%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E6%89%8B%E9%A0%86/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/performance_evaluation/jmeter%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E6%89%8B%E9%A0%86/</guid>
      <description>JMeter インストール手順  JMeter インストール手順  Java インストール zip 展開 Path を通す JMeter 設定  JMeter を起動する      Java インストール https://java.com/ja/download/win10.jsp
Windows 版 Java をダウンロードしインストーラーを実行する。
zip 展開 http://jmeter.apache.org/download_jmeter.cgi
Binaries の apache-jmeter-5.2.1.zip をダウンロードする。 zip を C:\Program Files に展開する。
Path を通す コントロール パネル\すべてのコントロール パネル項目\システム\システムの詳細設定\環境変数 で環境変数設定画面を開きシステム環境変数の Path に JMeter の bin を追加する（今回は C:\Program Files\apache-jmeter-5.2.1\bin）。
JMeter 設定 C:\Program Files\apache-jmeter-5.2.1\bin に jmeter.properties がある。 これを作業ディレクトリにコピーし，設定を変更する。 今回は日本語化，日付フォーマットを設定した。
language=jalocales.add=jajmeter.save.saveservice.timestamp_format=yyyy/MM/dd HH:mm:ss.SSSsampleresult.default.encoding=UTF-8JMeter を起動する 作業ディレクトリで JMeter を起動する。 オプションで設定ファイルを指定する。</description>
    </item>
    
    <item>
      <title>logmanでパフォーマンスモニターのカウンター開始／停止</title>
      <link>https://mktkdyt.github.io/post/performance_evaluation/logman%E3%81%A7%E3%83%91%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%B3%E3%82%B9%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%E3%81%AE%E3%82%AB%E3%82%A6%E3%83%B3%E3%82%BF%E3%83%BC%E9%96%8B%E5%A7%8B%E5%81%9C%E6%AD%A2/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/performance_evaluation/logman%E3%81%A7%E3%83%91%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%B3%E3%82%B9%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%E3%81%AE%E3%82%AB%E3%82%A6%E3%83%B3%E3%82%BF%E3%83%BC%E9%96%8B%E5%A7%8B%E5%81%9C%E6%AD%A2/</guid>
      <description>logmanでパフォーマンスモニターのカウンター開始／停止  logmanでパフォーマンスモニターのカウンター開始／停止  概要 WinRM でクライアントからホストに接続 カウンター一覧 カウンター状態確認 カウンター開始 カウンター停止    概要  WinRM でクライアントからホストに接続する。 logman コマンドでカウンターを開始する。 logman コマンドでカウンターを停止する。  WinRM でクライアントからホストに接続 &amp;gt; $targetHost = &amp;#34;web&amp;#34; &amp;gt; $id = &amp;#34;user&amp;#34; &amp;gt; $password = &amp;#34;password&amp;#34; &amp;gt; $securePassword = ConvertTo-SecureString -String $password -AsPlainText -Force &amp;gt; $cred = New-Object System.Management.Automation.PSCredential($id, $securePassword) &amp;gt; Enter-PSSession -ComputerName $targetHost -Credential $cred カウンター一覧 &amp;gt; logman query データ コレクター セット 種類 状態 ------------------------------------------------------------------------------- GAEvents トレース 実行中 PerfMonWeb カウンター 停止済み RTEvents トレース 実行中 Server Manager Performance Monitor カウンター 停止済み カウンター状態確認 &amp;gt; logman query PerfMonWeb 名前: PerfMonWeb 状態: 実行中 ルート パス: %systemdrive%\PerfLogs\Admin セグメント: オフ スケジュール: オフ 別のユーザーとして実行: SYSTEM 名前: PerfMonWeb\PerfMonWeb 種類: カウンター 出力場所: C:\PerfLogs\Admin\PerfMonWeb_05131446.</description>
    </item>
    
    <item>
      <title>Solr Cloud の可用性を検証する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/solr-cloud%E3%81%AE%E5%8F%AF%E7%94%A8%E6%80%A7%E3%82%92%E6%A4%9C%E8%A8%BC%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/solr-cloud%E3%81%AE%E5%8F%AF%E7%94%A8%E6%80%A7%E3%82%92%E6%A4%9C%E8%A8%BC%E3%81%99%E3%82%8B/</guid>
      <description>Solr Cloud の可用性を検証する Solr Cloud の可用性を検証しました．
node の管理 node が停止したら Failover するか，node が再起動したら Failback するか実験しました．
1個の node を停止する 全ての node が起動しているときの node 一覧とグラフです．
これらの node で shard1 の leader を停止してみます．
vagrant halt node2 node 一覧を見ると shard1 の leader が死んだことがすぐわかります．
グラフを見ると shard1 の leader が 192.168.33.22 -&amp;gt; 192.168.33.24 になりました．
このように node が停止したら自動で leader が切り替わることがわかりました．
1個の node を復旧する こんどは停止した node を起動します． また Cloud モードで起動します．
vagrant up node2 vagrant ssh node2 -c &amp;#34;sudo -u solr /opt/solr/bin/solr stop&amp;#34; vagrant ssh node2 -c &amp;#34;sudo -u solr /opt/solr/bin/solr start -cloud -s /var/solr/data -p 8983 -z 192.</description>
    </item>
    
    <item>
      <title>Solr Cloud を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/solr-cloud%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/solr-cloud%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>Solr Cloud を構築する Solr Cloud を Vagrant で構築します．
Solr Cloud を構築するには，Solr はもちろん ZooKeeper も必要です．
Solr Cloud イメージはこんな感じです．
 ZooKeeper : 3 Solr node: 4 shard : 2 replica : 2  Zookeeper 3 個，Solr node 4 個の計 7 個の VM を構築します．
構成 構成を以下に示します．
D:\vagrant\solrcloud ┣Vagrantfile ┣create_zkensemble.sh ┗create_solrnode.sh Vagrantfile Zookeeper 3 個，Solr node 4 個の計 7 個の VM を構築します．
Solr を Cloud モードで起動する際に ZooKeeper の接続先を指定する必要があるので Vagrantfile で接続先文字列を用意するのがポイントです．
# ZooKeeper 数 zk_cnt = 3 # Solr node 数 node_cnt = 4 Vagrant.</description>
    </item>
    
    <item>
      <title>Solr(Master-Slave)を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/solrmaster-slave%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/solrmaster-slave%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>Solr(Master-Slave)を構築する Vagrant で Solr を Master-Slave で構築しました．
Solr のバージョンは 6.2.0 です．
構成 Solr の構築はシェルでやることにしました．
D:\vagrant\solrmasterslave ┣Vagrantfile ┗create_solr.sh Vagrantfile  OS は CentOS 7 を使用します． プロビジョナでシェルを実行します．  slave_cnt = 2 Vagrant.configure(&amp;#34;2&amp;#34;) do |config| config.vm.box = &amp;#34;centos/7&amp;#34; config.vm.define &amp;#34;master&amp;#34; do | master | master.vm.hostname = &amp;#34;master&amp;#34; master.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.168.33.40&amp;#34; master.vm.provision :hosts, :sync_hosts =&amp;gt; true master.vm.provision :shell, path: &amp;#34;./create_solr.sh&amp;#34; end (1..slave_cnt).each do |i| config.vm.define &amp;#34;slave#{i}&amp;#34; do | slave | slave.vm.hostname = &amp;#34;slave#{i}&amp;#34; slave.</description>
    </item>
    
    <item>
      <title>Solr(Standalone) を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/solrstandalone%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/solrstandalone%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>Solr(Standalone) を構築する Vagrant で Solr を Standalone で構築しました．
Solr のバージョンは 6.2.0 です．
構成 Solr の構築はシェルでやることにしました．
D:\vagrant\solr-standalone ┣Vagrantfile ┗create_solr.sh Vagrantfile  OS は CentOS 7 を使用します． プロビジョナでシェルを実行します．  Vagrant.configure(&amp;#34;2&amp;#34;) do |config| config.vm.box = &amp;#34;centos/7&amp;#34; config.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.168.33.30&amp;#34; config.vm.provision :shell, path: &amp;#34;./create_solr.sh&amp;#34; end create_solr.sh  Java をインストールします． Solr のアーカイブを取得して展開しシェルを実行します． Solr で使用する Port を開放します．  # Java をインストールする yum install -y java-1.8.0-openjdk # Solr を構築する cd /usr/local/src/ yum install -y wget wget https://archive.</description>
    </item>
    
    <item>
      <title>WinRM(Windows Remote Management)設定手順</title>
      <link>https://mktkdyt.github.io/post/performance_evaluation/winrmwindowsremotemanagement%E8%A8%AD%E5%AE%9A%E6%89%8B%E9%A0%86/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/performance_evaluation/winrmwindowsremotemanagement%E8%A8%AD%E5%AE%9A%E6%89%8B%E9%A0%86/</guid>
      <description>WinRM(Windows Remote Management)設定手順 WinRMを設定しPowerShellでWindowsにリモートで接続出来るようにする。 これによりリモートデスクトップで接続することなくWebサーバのIISを止めたりIISのログをローテートしたり出来る。
 WinRM(Windows Remote Management)設定手順  ホスト側設定 クライアント側設定 クライアントからホストに接続 ホストから切断    ホスト側設定 接続先，接続される側の設定。
&amp;gt; winrm quickconfigWinRM サービスは、既にこのコンピューターで実行されています。WinRM は、管理用にこのコンピューターへのリモート アクセスを許可するように設定されていません。次の変更を行う必要があります:ローカル ユーザーにリモートで管理権限を付与するよう LocalAccountTokenFilterPolicy を構成してください。変更しますか [y/n]? yWinRM はリモート管理用に更新されました。ローカル ユーザーにリモートで管理権限を付与するよう LocalAccountTokenFilterPolicy を構成しました。クライアント側設定 接続元，接続する側の設定。
&amp;gt; winrm quickconfigWinRM はこのコンピューター上で要求を受信するように設定されていません。次の変更を行う必要があります:WinRM サービスを開始します。WinRM サービスの種類を遅延自動開始に設定します。変更しますか [y/n]? yWinRM は要求を受信するように更新されました。WinRM サービスの種類を正しく変更できました。WinRM サービスが開始されました。WSManFaultMessageProviderFaultWSManFaultMessage = このコンピューターのネットワーク接続の種類の 1 つが Public に設定されているため、WinRM ファイアウォール例外は機能しません。 ネットワーク接続の種類を Domain または Private に変更して、やり直してください。エラー番号: -2144108183 0x80338169このコンピューターのネットワーク接続の種類の 1 つが Public に設定されているため、WinRM ファイアウォール例外は機能しません。 ネットワーク接続の種類を Domain または Private に変更して、やり直してください。上記のようなエラーが発生した場合は -SkipNetworkProfileCheck を付与し Enable-PSRemoting を実行する。</description>
    </item>
    
    <item>
      <title>WSL オフラインインストール手順</title>
      <link>https://mktkdyt.github.io/post/performance_evaluation/wsl%E3%82%AA%E3%83%95%E3%83%A9%E3%82%A4%E3%83%B3%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E6%89%8B%E9%A0%86/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/performance_evaluation/wsl%E3%82%AA%E3%83%95%E3%83%A9%E3%82%A4%E3%83%B3%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E6%89%8B%E9%A0%86/</guid>
      <description>WSL オフラインインストール手順  WSL オフラインインストール手順  WSL 有効化 ディストリビューションダウンロード ディストリビューションインストール ディストリビューション初期化    WSL 有効化 &amp;gt; Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux ディストリビューションダウンロード https://docs.microsoft.com/ja-jp/windows/wsl/install-manual から目的のOSをダウンロードする。
ディストリビューションインストール &amp;gt; Add-AppxPackage C:\Users\usename\Downloads\CanonicalGroupLimited.Ubuntu18.04onWindows_1804.2018.817.0_x64__79rhkp1fndgsc.Appx ディストリビューション初期化 スタートメニューに表示されるディストリビューションをクリックし，ユーザ名，パスワードを設定する（仮想マシンのアカウントと同じユーザ名，パスワードとした）。</description>
    </item>
    
    <item>
      <title>ZooKeeper Ensemble を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/zookeeper-ensemble%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/zookeeper-ensemble%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>ZooKeeper Ensemble を構築する ZooKeeper も冗長構成を取れるように ZooKeeper Ensemble を構築します． ZooKeeper のバージョンは 3.4.14 です．
ZooKeeper Ensemble ZooKeeper の可用性を高めるために複数台で　Ensemble 構成を取ります． ZooKeeper では Ensemble の過半数が動作していることがサービスの継続条件のため，奇数台で構築するのがベストなようです．
例
4 台のマシンで ZooKeeper Ensemble を構築した場合，1 台のマシンがダウンしても残り 3 台で過半数となるためサービスを継続することができますが， 2 台のマシンがダウンすると残り 2 台で過半数にならないためサービスを継続できなくなってしまいます． つまり 1 / 4，25 % のダウンを許容します．
5 台のマシンで ZooKeeper Ensemble を構築した場合，2 台のマシンがダウンしても残り 3 台で過半数となるためサービスを継続することができますが， 3 台のマシンがダウンすると残り 2 台で過半数にならないためサービスを継続できなくなってしまいます． つまり 2 / 5，40 % のダウンを許容します．
6 台のマシンで ZooKeeper Ensemble を構築した場合，2 台のマシンがダウンしても残り 4 台で過半数となるためサービスを継続することができますが， 3 台のマシンがダウンすると残り 3 台で過半数にならないためサービスを継続できなくなってしまいます． つまり 2 / 6，33 % のダウンを許容します．</description>
    </item>
    
    <item>
      <title>ZooKeeper を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/zookeeper%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/zookeeper%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>ZooKeeper を構築する Solr Cloud を構築するには ZooKeeper を構築する必要があります．
そこで Vagrant で ZooKeeper を構築しました． ZooKeeper のバージョンは 3.4.14 です．
ZooKeeper??? Solr Cloud を構築する上で必須なサービスです．
Solr Cloud では collection を 複数の shard に分けることでインデックスを分散し，さらに shard を replication により複製し冗長構成をとることで可用性を向上させます．
ZooKeeper は分散アプリケーションの管理をおこない，Solr Cloud において shard の replica が格納された Solr の各 node の状態を管理します．
構成 ZooKeeper の構築はシェルでやることにしました．
D:\vagrant\zk ┣Vagrantfile ┗create_zk.sh Vagrantfile  OS は CentOS 7 を使用します． プロビジョナでシェルを実行します．  Vagrant.configure(&amp;#34;2&amp;#34;) do |config| config.vm.box = &amp;#34;centos/7&amp;#34; config.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.168.33.10&amp;#34; config.vm.provision :shell, path: &amp;#34;.</description>
    </item>
    
    <item>
      <title>シェルティー判定 AI を作成する</title>
      <link>https://mktkdyt.github.io/post/machine_learning/%E3%82%B7%E3%82%A7%E3%83%AB%E3%83%86%E3%82%A3%E3%83%BC%E5%88%A4%E5%AE%9Aai%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/machine_learning/%E3%82%B7%E3%82%A7%E3%83%AB%E3%83%86%E3%82%A3%E3%83%BC%E5%88%A4%E5%AE%9Aai%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B/</guid>
      <description>シェルティー判定 AI を作成する 謝辞 まず初めに参考にさせていただきました。 大変感謝申し上げます。
https://qiita.com/yottyann1221/items/a08300b572206075ee9f https://qiita.com/tomo_20180402/items/e8c55bdca648f4877188 https://qiita.com/mainvoidllll/items/db991dc30d3ddced6250 https://newtechnologylifestyle.net/keras_imagedatagenerator/
掲載している画像はフリー画像を使用させていただきました。 https://pixabay.com/ja/
序 機械学習に入門しました。 ざっとぐぐったところこんな感じで進めていくようです。
 大量の画像を用意する 教師／テストデータを作成する モデルを作成する モデルで評価する  今回は、画像認識でシェルティー判定プログラムを作成することにしました。
環境構築 Windows 10 に chocolatey で python3 を入れました。 venv で仮想環境を構築し、必要なライブラリを入れます。
&amp;gt; mkdir -p e:\python\ml &amp;gt; cd e:\python\ml &amp;gt; python -m venv ml &amp;gt; .\ml\Scripts\activate (ml)&amp;gt; pip install requests (ml)&amp;gt; pip install beautifulsoup4 # lxml を入れないと下のエラーが出る # bs4.FeatureNotFound: Couldn&amp;#39;t find a tree builder with the features you requested: lxml. Do you need to install a parser library?</description>
    </item>
    
    <item>
      <title>パフォーマンスモニター設定手順</title>
      <link>https://mktkdyt.github.io/post/performance_evaluation/%E3%83%91%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%B3%E3%82%B9%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%E8%A8%AD%E5%AE%9A%E6%89%8B%E9%A0%86/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/performance_evaluation/%E3%83%91%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%B3%E3%82%B9%E3%83%A2%E3%83%8B%E3%82%BF%E3%83%BC%E8%A8%AD%E5%AE%9A%E6%89%8B%E9%A0%86/</guid>
      <description>パフォーマンスモニター設定手順 Webサーバー，DBサーバーで実施する。
 パフォーマンスモニター設定手順  カウンター作成  perfMonCreater.bat counter_list.txt   カウンター確認 カウンター実行    カウンター作成 下記ファイルをWebサーバーの任意のディレクトリに配置する。
 perfMonCreater.bat counter_list.txt  管理者権限で perfMonCreater.bat を実行する。
perfMonCreater.bat  logman コマンドでカウンターを作成する。  REM -m start stop 開始，終了を手動にする。 REM -f bin ログの形式を指定する。 REM -v mmddhhmm ログのファイル名のサフィックスを日時にする。 REM -si 10 サンプリング間隔を 10 秒に設定する。 REM -cf 収集するパフォーマンスカウンターをファイルで指定する。 logman create counter PerfMon -m start stop -f bin -v mmddhhmm -si 10 -cf .\counter_list.txt @pause counter_list.txt  取得したいパフォーマンスカウンターのリスト。 Webで IIS や ASP.</description>
    </item>
    
    <item>
      <title>メトリクス監視環境構築手順</title>
      <link>https://mktkdyt.github.io/post/performance_evaluation/%E3%83%A1%E3%83%88%E3%83%AA%E3%82%AF%E3%82%B9%E7%9B%A3%E8%A6%96%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89%E6%89%8B%E9%A0%86/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/performance_evaluation/%E3%83%A1%E3%83%88%E3%83%AA%E3%82%AF%E3%82%B9%E7%9B%A3%E8%A6%96%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89%E6%89%8B%E9%A0%86/</guid>
      <description>メトリクス監視環境構築手順  JMeter を CUI で実行している際の JMeter のメトリクスを Grafana で可視化します。 Windows Server のメトリクスを Grafana で可視化します。   メトリクス監視環境構築手順  概要 Telegraf  インストール telegraf.conf 起動 サービス化 サービス起動／停止   Docker コンテナ作成  ディレクトリ influxdb.conf docker-compose.yml コンテナ作成 コンテナ停止 コンテナ開始   InfluxDB  動作確認 DB 作成   Grafana  管理者作成 サーバメトリクス取得設定  data source 追加 フォルダ作成 Dashboard 作成   JMeter メトリクス取得設定  data source 追加 Dashboard 追加     JMeter シナリオ編集  Backend Listener 追加      概要    ソフト 内容     InfluxDB 時系列 DB です。メトリクスをここで収集します。   Grafana 様々なデータソースを可視化する GUI ツールです。   Telegraf 様々なメトリクスを InfluxDB に収集するコレクタです。     JMeter のメトリクスを InfluxDB に流し，Grafana で可視化します。  JMeter -&amp;gt; InfluxDB -&amp;gt; Grafana   対象の Windows に Telegraf をインストールし，Telegraf から Windows のメトリクスを InfluxDB に流し，Grafana で可視化します。  Telegraf -&amp;gt; InfluxDB -&amp;gt; Grafana    Telegraf パフォーマンスを見たい Windows にインストールします。</description>
    </item>
    
    <item>
      <title>性能評価実施手順</title>
      <link>https://mktkdyt.github.io/post/performance_evaluation/%E6%80%A7%E8%83%BD%E8%A9%95%E4%BE%A1%E5%AE%9F%E6%96%BD%E6%89%8B%E9%A0%86/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/performance_evaluation/%E6%80%A7%E8%83%BD%E8%A9%95%E4%BE%A1%E5%AE%9F%E6%96%BD%E6%89%8B%E9%A0%86/</guid>
      <description>性能評価実施手順  性能評価実施手順  手順 Docker 起動 性能評価前処理  フルバックアップのリストア プランキャッシュ削除 データ量取得 Webサーバ／DBサーバ処理   性能評価実施  JMeter 実行 Grafana でメトリクス監視 JMeter 停止   性能評価後処理 性能評価結果回収  IISログ パフォーマンスモニターのログ SSMSでレポートを出力 データ量確認      手順 Docker でコンテナを起動した後，測定毎に下記処理を実施する。
 性能評価前処理  対象のシナリオのデータ量に該当するDBのフルバックアップをリストアする。 DBのプランキャッシュを削除する。 データ量を取得する。 WinRMでWebサーバに接続する。  IISを停止する。 IISログをローテートする。 IISを起動する。 パフォーマンスモニターのカウンターを開始する。   WinRMでDBサーバに接続する。  パフォーマンスモニターのカウンターを開始する。     性能評価実施  JMeterを実行する。 Grafanaでメトリクスを監視する。 JMeterを終了する。   性能評価後処理  WinRMでWebサーバに接続する。  パフォーマンスモニターのカウンターを停止する。 IISを停止する。 IISログをローテートする。 IISを起動する。   WinRMでDBサーバに接続する。  パフォーマンスモニターのカウンターを停止する。     性能評価結果回収  IISログを回収する。 パフォーマンスモニターのログを回収する。 Grafanaのデータをエクスポートする。 SSMSでレポートを出力する。 データ量を確認する。    Docker 起動  Grafana, InfluxDB のコンテナを起動する。  cd C:\LoadTest\Docker docker-compose up -d 性能評価前処理 フルバックアップのリストア  SSMS を起動し DB サーバに接続する。 対象のデータベースを右クリックし タスク\オフライン でデータベースの接続を切断する。 対象のデータベースを右クリックし タスク\復元\データベース で デバイス に該当するフルバックアップを指定し OK をクリックする。  プランキャッシュ削除  SSMS で下記クエリを実行する。  DBCC FREEPROCCACHE データ量取得  性能評価実施前にデータ量を取得する。 SSMS で下記クエリを実行する。 テーブル名は適宜修正する。  DECLARE @now datetime; SET @now = GETDATE(); select &amp;#39;XXX&amp;#39; as &amp;#39;機能&amp;#39;, (select count(*) from XXX) as &amp;#39;件数&amp;#39;, @now as &amp;#39;検索日時&amp;#39; union all select &amp;#39;YYY&amp;#39; as &amp;#39;機能&amp;#39;, (select count(*) from YYY) as &amp;#39;件数&amp;#39;, @now as &amp;#39;検索日時&amp;#39; union all select &amp;#39;ZZZ&amp;#39; as &amp;#39;機能&amp;#39;, (select count(*) from ZZZ) as &amp;#39;件数&amp;#39;, @now as &amp;#39;検索日時&amp;#39; Webサーバ／DBサーバ処理  PowerShell を起動し下記コマンドを実行する。  WinRMでWebサーバに接続する。  IISを停止する。 IISログをローテートする。 IISを起動する。 パフォーマンスモニターのカウンターを開始する。   WinRMでDBサーバに接続する。  パフォーマンスモニターのカウンターを開始する。     日時は適宜設定すること。  .</description>
    </item>
    
    <item>
      <title>Pigで辞書を当てる</title>
      <link>https://mktkdyt.github.io/post/bigdata/pig%E3%81%A7%E8%BE%9E%E6%9B%B8%E3%82%92%E5%BD%93%E3%81%A6%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/pig%E3%81%A7%E8%BE%9E%E6%9B%B8%E3%82%92%E5%BD%93%E3%81%A6%E3%82%8B/</guid>
      <description>keywords.tsv
Hoge Fuga Piyo  辞書を読み込み，1行に変換する。  キーワードを OR で当てるため。    keywords_as_one_line = common_function.load_dictionary_as_one_line(&amp;#39;keywords.tsv&amp;#39;, &amp;#39;|&amp;#39;) def load_dictionary_as_one_line(dictionary_file, separator): with open(dictionary_file) as f: lines_one_str = &amp;#39;&amp;#39; # a\nb\nc\n -&amp;gt; a|b|c|d lines = f.readlines() for line in lines: word = line.rstrip(os.linesep) if(word != &amp;#39;&amp;#39;): lines_one_str += word + separator return lines_one_str[:-1]  本文に matches で辞書のキーワードが含まれるか見る。  Pig テンプレートに1行に変換したキーワードを埋め込む。    COND = { &amp;#39;$KEYWORDS&amp;#39;: f&amp;#39;.*({keywords_as_one_line}).*&amp;#39;, }_ common_function.translate_pig(&amp;#39;extract_text_template.pig&amp;#39;, &amp;#39;extract_text.pig&amp;#39;, COND) def translate_pig(template: str, output: str, d: {str, str}): for i, (k, v) in enumerate(d.</description>
    </item>
    
    <item>
      <title>Pig使い方まとめ</title>
      <link>https://mktkdyt.github.io/post/bigdata/pig%E4%BD%BF%E3%81%84%E6%96%B9%E3%81%BE%E3%81%A8%E3%82%81/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/pig%E4%BD%BF%E3%81%84%E6%96%B9%E3%81%BE%E3%81%A8%E3%82%81/</guid>
      <description>テキスト処理 改行除く  ^M（CR）も除く。  REPLACE(REPLACE(REPLACE(REPLACE(text, &amp;#39;\\t&amp;#39;, &amp;#39;&amp;#39;), &amp;#39;\\r\\n&amp;#39;, &amp;#39;&amp;#39;), &amp;#39;\\n&amp;#39;, &amp;#39;&amp;#39;), &amp;#39;\\\\^M&amp;#39;, &amp;#39;&amp;#39;) CONCAT  文字列を結合する。  CONCAT(&amp;#39;https://sample.jp?user=&amp;#39;, user) 条件演算 INDEXOF  指定した文字列がカラムに含まれているかを見る。  -- text に「プレゼント」が含まれていないレコードを抽出する FILTERED = FILTER DATA BY INDEXOF(text, &amp;#39;プレゼント&amp;#39;) &amp;lt; 0 -- text に「ビッグデータ」が含まれているレコードを抽出する FILTERED = FILTER DATA BY INDEXOF(text, &amp;#39;ビッグデータ&amp;#39;) &amp;gt; 0 日時フィルター  ToDate() で文字列を日時に変換可能。  -- 2019-05-31 00:00:00 から 2019-06-01 00:00:00 に登録されたユーザを抽出する FILTERED_USER = FILTER USER BY ToDate(&amp;#39;2019-05-31 00:00:00&amp;#39;,&amp;#39;yyyy-MM-dd HH:mm:ss&amp;#39;) &amp;lt;= ToDate(created,&amp;#39;yyyy-MM-dd HH:mm:ss&amp;#39;) AND ToDate(created,&amp;#39;yyyy-MM-dd HH:mm:ss&amp;#39;) &amp;lt; ToDate(&amp;#39;2019-06-01 00:00:00&amp;#39;,&amp;#39;yyyy-MM-dd HH:mm:ss&amp;#39;); 関係演算 ユニークを取る -- 重複を除く UNIQ_USER = DISTINCT USER; 取得件数を制限する -- 5 件に制限する L = LIMIT DATA 5; 集合演算 内部結合する USER1 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); USER2 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); J = JOIN USER1 BY id, USER2 BY id; 外部結合する USER1 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); USER2 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); J = JOIN USER1 BY id LEFT OUTER, USER2 BY id; 差集合を取る  JOIN して片方の Relation が NULL なレコードを抽出する。  USER1 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); USER2 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); J = JOIN USER1 BY id LEFT OUTER, USER2 BY id; USER1_MINUS_USER2 = FILTER J BY USER2::id is NULL; 積集合を取る  JOIN して片方の Relation が not NULL なレコードを抽出する。  USER1 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); USER2 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); J = JOIN USER1 BY id LEFT OUTER, USER2 BY id; USER1_AND_USER2 = FILTER J BY USER2::id is not NULL; 出力 TSV 出力 FS -rm -r -f -skipTrash /tmp/some_dir/ STORE DATA INTO &amp;#39;/tmp/some_dir&amp;#39; USING PigStorage(&amp;#39;\t&amp;#39;);  -schema オプションを付与することで load するときにカラム名と型を指定しなくてよくなる。  FS -rm -r -f -skipTrash /tmp/some_dir/ STORE DATA INTO &amp;#39;/tmp/some_dir&amp;#39; USING PigStorage(&amp;#39;\t&amp;#39;, &amp;#39;-schema&amp;#39;); ORC 出力  データ量を削減したい場合に使用する。  FS -rm -r -f -skipTrash /tmp/some_dir/ STORE DATA INTO &amp;#39;/tmp/some_dir&amp;#39; USING OrcStorage(&amp;#39;-c ZLIB&amp;#39;); Pig 実行 コマンド実行  Pig ファイルを指定し pig コマンドを実行する。  pig test.</description>
    </item>
    
    <item>
      <title>ビッグデータ分析で使用するPythonコード一覧</title>
      <link>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%A7%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8Bpython%E3%82%B3%E3%83%BC%E3%83%89%E4%B8%80%E8%A6%A7/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%A7%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8Bpython%E3%82%B3%E3%83%BC%E3%83%89%E4%B8%80%E8%A6%A7/</guid>
      <description>環境構築  必要に応じて仮想環境を作る。  仮想環境作成 $ python3 -m venv test 仮想環境有効化 $ source test/bin/activate (test)$ 仮想環境無効化 (test)$ deactivate $ 文字列処理 文字列を切り出す  [開始インデックス:終了文字番号(インデックスではないことに注意)]とする。  s = &amp;#34;2019-06-01&amp;#34; print(f&amp;#34;{s[0:4]}-{s[5:7]}-{s[8:10]}&amp;#34;) エスケープ 波括弧のエスケープ  波括弧は波括弧でエスケープする。  var = &amp;#39;aiuto&amp;#39; print( f&amp;#34;val is {{{var}}}&amp;#34; ) ディレクトリ操作 ディレクトリ作成 import os os.makidirs(&amp;#39;tmp&amp;#39;, exist_ok=True) class  プロパティ等を別ファイルにしたい場合等に使用する。  classsample ├── main.py └── prop └── user_property.py main.py
from prop.user_property import UserProperty user_property = UserProperty({&amp;#39;first_name&amp;#39;: &amp;#39;イチロー&amp;#39;, &amp;#39;family_name&amp;#39;: &amp;#39;テスト&amp;#39;}) print(f&amp;#39;{user_property.FAMILY_NAME} {user_property.</description>
    </item>
    
    <item>
      <title>ビッグデータ分析で使用するシェルコマンド一覧</title>
      <link>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%A7%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8B%E3%82%B7%E3%82%A7%E3%83%AB%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E4%B8%80%E8%A6%A7/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%A7%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8B%E3%82%B7%E3%82%A7%E3%83%AB%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E4%B8%80%E8%A6%A7/</guid>
      <description>ビッグデータ分析で使用してきたシェルコマンドをまとめた。
ターミナル表示 echo で文字列エスケープ $ echo &amp;#34;\&amp;#34;&amp;#34; &amp;#34; echo で改行表示  -e で改行を表示出来る。  $ txt=&amp;#34;a\nb\nc&amp;#34; $ echo -e &amp;#34;$txt&amp;#34; a b c テキスト処理 文字列から offset を指定して抽出する  日付文字列から年月日を抽出する際に使用する。  $ d=&amp;#34;20190630&amp;#34; $ echo ${d:0:4} 2019 $ echo ${d:4:2} 06 文字列の長さを取得する $ txt=&amp;#34;abcdef&amp;#34; $ echo ${#txt} 6 ファイル処理 tsvから特定の列を抽出する  cut コマンドで取り出せる。 ただし，複数列取り出せても順番を入れ替えることは出来ない。  $ cat test.tsv | cut -f3,4  awk でも可能。 awk だと列を入れ替えることができる。 -F で区切り文字を指定する  $ awk -F&amp;#39;\t&amp;#39; &amp;#39;{print $4 &amp;#34;\t&amp;#34; $3}&amp;#39; -f test.</description>
    </item>
    
    <item>
      <title>ビッグデータ分析のエラーハンドリング</title>
      <link>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%8F%E3%83%B3%E3%83%89%E3%83%AA%E3%83%B3%E3%82%B0/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%8F%E3%83%B3%E3%83%89%E3%83%AA%E3%83%B3%E3%82%B0/</guid>
      <description>リトライ時の処理スキップ  Pig 実行前に Pig の成果物が既に HDFS に存在するか確認し存在する場合は処理をスキップするようにした。 強制実行オプションを設け，指定された場合は成果物が既にある処理も実行されるようにした。  # 強制実行オプション @click.option( &amp;#39;--force&amp;#39;, &amp;#39;-f&amp;#39;, &amp;#39;force&amp;#39;, is_flag=True, help=&amp;#39;強制実行フラグ。これを立てたら既に抽出済みの処理も再実行する。&amp;#39; ) def exists_in_hdfs(hdfs_path: str) -&amp;gt; bool: &amp;#34;&amp;#34;&amp;#34;HDFS上のパスに指定したディレクトリ・ファイルが存在しているか否かを返す Arguments: hdfs_path {str} -- HDFS上のパス Returns: bool -- 存在していればTrue, していなければFalse &amp;#34;&amp;#34;&amp;#34; result = subprocess.run([&amp;#34;hadoop&amp;#34;, &amp;#34;fs&amp;#34;, &amp;#34;-test&amp;#34;, &amp;#34;-e&amp;#34;, hdfs_path]) if result.returncode == 0: return True else: return False def exists_all_in_hdfs(src_list) -&amp;gt; bool: &amp;#34;&amp;#34;&amp;#34;リストで指定したディレクトリ・ファイルが全て HDFS に存在するかを検証します。 Arguments: src_tupple -- HDFS のパス Returns: bool -- 全て存在すれば True，それ以外の場合は False &amp;#34;&amp;#34;&amp;#34; for src in src_list: if(not exists_in_hdfs(src)): logger.</description>
    </item>
    
    <item>
      <title>外部 API 並列処理</title>
      <link>https://mktkdyt.github.io/post/bigdata/%E5%A4%96%E9%83%A8api%E4%B8%A6%E5%88%97%E5%87%A6%E7%90%86/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/%E5%A4%96%E9%83%A8api%E4%B8%A6%E5%88%97%E5%87%A6%E7%90%86/</guid>
      <description>HDFS から対象のIDを取り出す。  uniq で重複排除する。   標準入力を split で n 分割する。  行数にデータ件数の 1/n を指定することで標準入力を n 分割する。 分割されたファイルは tmp/000* の形式で出力される（分割したらファイル出力されてしまう）。    split_cnt = 10 text_hdfs_dir = &amp;#39;/text&amp;#39; tmp_dir = &amp;#39;tmp&amp;#39; c = f&amp;#39;hadoop fs -cat \&amp;#39;{text_hdfs_dir}/part-*\&amp;#39;| cut -f1 | grep -E \&amp;#39;^[0-9]{{1,30}}$\&amp;#39;| sort | uniq | split -l $(($(hadoop fs -cat \&amp;#39;{text_hdfs_dir}/part-*\&amp;#39;| cut -f1 | grep -E \&amp;#39;^[0-9]{{1,30}}$\&amp;#39;| sort | uniq | wc -l)/{split_cnt}+1)) -d -a 5 - {tmp_dir}/&amp;#39; subprocess.</description>
    </item>
    
    <item>
      <title>Hadoopコマンドまとめ</title>
      <link>https://mktkdyt.github.io/post/bigdata/hadoop%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%BE%E3%81%A8%E3%82%81/</link>
      <pubDate>Thu, 14 Jan 2021 17:22:56 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/hadoop%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%BE%E3%81%A8%E3%82%81/</guid>
      <description>Hadoop コマンドまとめ ジョブ関連 Hadoop のジョブを一覧表示する $ yarn application -list Hadoop のジョブを強制終了する $ yarn application -kill $application_id queue を変更する $ yarn application -movetoqueue $application_id -queue $queue_name HDFS ディレクトリ操作 HDFS のディレクトリの中身を確認する $ hadoop fs -ls /tmp/some_dir HDFS のディレクトリを削除する $ hadoop fs -rm -r /tmp/some_dir HDFS にディレクトリを作成する $ hadoop fs -mkdir /tmp/some_dir HDFS ファイル操作 HDFS にローカルのファイルを置く $ hadoop fs -put /home/user/some.tsv /tmp/some_dir/rawdata.tsv HDFS の中身を表示する $ hadoop fs -cat /tmp/some_dir/rawdata.tsv HDFS の中身をローカルに吐き出す HDFS に TSV で格納した場合。</description>
    </item>
    
  </channel>
</rss>
