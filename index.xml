<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mktkdyt</title>
    <link>https://mktkdyt.github.io/</link>
    <description>Recent content on mktkdyt</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Thu, 14 Jan 2021 17:24:23 +0900</lastBuildDate><atom:link href="https://mktkdyt.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI をアプリに組み込む</title>
      <link>https://mktkdyt.github.io/post/machine_learning/ai%E3%82%92%E3%82%A2%E3%83%97%E3%83%AA%E3%81%AB%E7%B5%84%E3%81%BF%E8%BE%BC%E3%82%80/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/machine_learning/ai%E3%82%92%E3%82%A2%E3%83%97%E3%83%AA%E3%81%AB%E7%B5%84%E3%81%BF%E8%BE%BC%E3%82%80/</guid>
      <description>AI をアプリに組み込む シェルティー判定AIを作成する で作成したシェルティー判定 AI を Flask に組み込んでみます。
構成 Vagrant で構築した ubuntu 上で実施しました。 IP は 192.168.33.31 です。
~/python/api├─app.py├─ai.py├─model : 事前に作成したモデル│ ├─model_predict.json│ └─model_predict.hdf5├─static│ ├─favicon.ico : ファビコン（任意）│ └─style.css : スタイルシート├─templates : 画面テンプレート│ └─index.html├─images : アップロードされた画像を格納するディレクトリ└─uwsgi.ini : uWSGI の設定ファイルイメージ アプリケーション配備先を用意する $ mkdir -p ~/python/api $ cd ~/python/api $ python3 -m venv api $ source api/bin/activate # ai の実行に必要なライブラリをインストールする $ pip install werkzeug $ pip install numpy==1.</description>
    </item>
    
    <item>
      <title>Elasticsearch を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/elasticsearch%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/elasticsearch%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>Elasticsearch を構築する ローカルで Elasticsearch を構築しました。 Elasticsearch 用に 3台，Kibana 用に 1台 VM を立てました。
VM 作成 Vagrantfile を作成して vagrant up します。
# Elasticsearch ノード数 es_cnt = 3 cnt = 4 Vagrant.configure(&amp;#34;2&amp;#34;) do |config| config.vm.box = &amp;#34;ubuntu/bionic64&amp;#34; config.vm.synced_folder &amp;#34;./share&amp;#34;, &amp;#34;/home/vagrant/share&amp;#34;, owner: &amp;#34;vagrant&amp;#34;, group: &amp;#34;vagrant&amp;#34; #--- Elasticsearch 構築 ---# (1..es_cnt).each do |i| config.vm.define &amp;#34;es#{i}&amp;#34; do | es | es.disksize.size = &amp;#39;50GB&amp;#39; es.vm.provider &amp;#34;virtualbox&amp;#34; do |vb| vb.memory = 8192 end es.vm.hostname = &amp;#34;es#{i}&amp;#34; es.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.</description>
    </item>
    
    <item>
      <title>Solr Cloud の可用性を検証する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/solr-cloud%E3%81%AE%E5%8F%AF%E7%94%A8%E6%80%A7%E3%82%92%E6%A4%9C%E8%A8%BC%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/solr-cloud%E3%81%AE%E5%8F%AF%E7%94%A8%E6%80%A7%E3%82%92%E6%A4%9C%E8%A8%BC%E3%81%99%E3%82%8B/</guid>
      <description>Solr Cloud の可用性を検証する Solr Cloud の可用性を検証しました．
node の管理 node が停止したら Failover するか，node が再起動したら Failback するか実験しました．
1個の node を停止する 全ての node が起動しているときの node 一覧とグラフです．
これらの node で shard1 の leader を停止してみます．
vagrant halt node2 node 一覧を見ると shard1 の leader が死んだことがすぐわかります．
グラフを見ると shard1 の leader が 192.168.33.22 -&amp;gt; 192.168.33.24 になりました．
このように node が停止したら自動で leader が切り替わることがわかりました．
1個の node を復旧する こんどは停止した node を起動します． また Cloud モードで起動します．
vagrant up node2 vagrant ssh node2 -c &amp;#34;sudo -u solr /opt/solr/bin/solr stop&amp;#34; vagrant ssh node2 -c &amp;#34;sudo -u solr /opt/solr/bin/solr start -cloud -s /var/solr/data -p 8983 -z 192.</description>
    </item>
    
    <item>
      <title>Solr Cloud を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/solr-cloud%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/solr-cloud%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>Solr Cloud を構築する Solr Cloud を Vagrant で構築します．
Solr Cloud を構築するには，Solr はもちろん ZooKeeper も必要です．
Solr Cloud イメージはこんな感じです．
 ZooKeeper : 3 Solr node: 4 shard : 2 replica : 2  Zookeeper 3 個，Solr node 4 個の計 7 個の VM を構築します．
構成 構成を以下に示します．
D:\vagrant\solrcloud ┣Vagrantfile ┣create_zkensemble.sh ┗create_solrnode.sh Vagrantfile Zookeeper 3 個，Solr node 4 個の計 7 個の VM を構築します．
Solr を Cloud モードで起動する際に ZooKeeper の接続先を指定する必要があるので Vagrantfile で接続先文字列を用意するのがポイントです．
# ZooKeeper 数 zk_cnt = 3 # Solr node 数 node_cnt = 4 Vagrant.</description>
    </item>
    
    <item>
      <title>Solr(Master-Slave)を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/solrmaster-slave%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/solrmaster-slave%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>Solr(Master-Slave)を構築する Vagrant で Solr を Master-Slave で構築しました．
Solr のバージョンは 6.2.0 です．
構成 Solr の構築はシェルでやることにしました．
D:\vagrant\solrmasterslave ┣Vagrantfile ┗create_solr.sh Vagrantfile  OS は CentOS 7 を使用します． プロビジョナでシェルを実行します．  slave_cnt = 2 Vagrant.configure(&amp;#34;2&amp;#34;) do |config| config.vm.box = &amp;#34;centos/7&amp;#34; config.vm.define &amp;#34;master&amp;#34; do | master | master.vm.hostname = &amp;#34;master&amp;#34; master.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.168.33.40&amp;#34; master.vm.provision :hosts, :sync_hosts =&amp;gt; true master.vm.provision :shell, path: &amp;#34;./create_solr.sh&amp;#34; end (1..slave_cnt).each do |i| config.vm.define &amp;#34;slave#{i}&amp;#34; do | slave | slave.vm.hostname = &amp;#34;slave#{i}&amp;#34; slave.</description>
    </item>
    
    <item>
      <title>Solr(Standalone) を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/solrstandalone%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/solrstandalone%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>Solr(Standalone) を構築する Vagrant で Solr を Standalone で構築しました．
Solr のバージョンは 6.2.0 です．
構成 Solr の構築はシェルでやることにしました．
D:\vagrant\solr-standalone ┣Vagrantfile ┗create_solr.sh Vagrantfile  OS は CentOS 7 を使用します． プロビジョナでシェルを実行します．  Vagrant.configure(&amp;#34;2&amp;#34;) do |config| config.vm.box = &amp;#34;centos/7&amp;#34; config.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.168.33.30&amp;#34; config.vm.provision :shell, path: &amp;#34;./create_solr.sh&amp;#34; end create_solr.sh  Java をインストールします． Solr のアーカイブを取得して展開しシェルを実行します． Solr で使用する Port を開放します．  # Java をインストールする yum install -y java-1.8.0-openjdk # Solr を構築する cd /usr/local/src/ yum install -y wget wget https://archive.</description>
    </item>
    
    <item>
      <title>ZooKeeper Ensemble を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/zookeeper-ensemble%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/zookeeper-ensemble%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>ZooKeeper Ensemble を構築する ZooKeeper も冗長構成を取れるように ZooKeeper Ensemble を構築します． ZooKeeper のバージョンは 3.4.14 です．
ZooKeeper Ensemble ZooKeeper の可用性を高めるために複数台で　Ensemble 構成を取ります． ZooKeeper では Ensemble の過半数が動作していることがサービスの継続条件のため，奇数台で構築するのがベストなようです．
例
4 台のマシンで ZooKeeper Ensemble を構築した場合，1 台のマシンがダウンしても残り 3 台で過半数となるためサービスを継続することができますが， 2 台のマシンがダウンすると残り 2 台で過半数にならないためサービスを継続できなくなってしまいます． つまり 1 / 4，25 % のダウンを許容します．
5 台のマシンで ZooKeeper Ensemble を構築した場合，2 台のマシンがダウンしても残り 3 台で過半数となるためサービスを継続することができますが， 3 台のマシンがダウンすると残り 2 台で過半数にならないためサービスを継続できなくなってしまいます． つまり 2 / 5，40 % のダウンを許容します．
6 台のマシンで ZooKeeper Ensemble を構築した場合，2 台のマシンがダウンしても残り 4 台で過半数となるためサービスを継続することができますが， 3 台のマシンがダウンすると残り 3 台で過半数にならないためサービスを継続できなくなってしまいます． つまり 2 / 6，33 % のダウンを許容します．</description>
    </item>
    
    <item>
      <title>ZooKeeper を構築する</title>
      <link>https://mktkdyt.github.io/post/full_text_search/zookeeper%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/full_text_search/zookeeper%E3%82%92%E6%A7%8B%E7%AF%89%E3%81%99%E3%82%8B/</guid>
      <description>ZooKeeper を構築する Solr Cloud を構築するには ZooKeeper を構築する必要があります．
そこで Vagrant で ZooKeeper を構築しました． ZooKeeper のバージョンは 3.4.14 です．
ZooKeeper??? Solr Cloud を構築する上で必須なサービスです．
Solr Cloud では collection を 複数の shard に分けることでインデックスを分散し，さらに shard を replication により複製し冗長構成をとることで可用性を向上させます．
ZooKeeper は分散アプリケーションの管理をおこない，Solr Cloud において shard の replica が格納された Solr の各 node の状態を管理します．
構成 ZooKeeper の構築はシェルでやることにしました．
D:\vagrant\zk ┣Vagrantfile ┗create_zk.sh Vagrantfile  OS は CentOS 7 を使用します． プロビジョナでシェルを実行します．  Vagrant.configure(&amp;#34;2&amp;#34;) do |config| config.vm.box = &amp;#34;centos/7&amp;#34; config.vm.network &amp;#34;private_network&amp;#34;, ip: &amp;#34;192.168.33.10&amp;#34; config.vm.provision :shell, path: &amp;#34;.</description>
    </item>
    
    <item>
      <title>シェルティー判定 AI を作成する</title>
      <link>https://mktkdyt.github.io/post/machine_learning/%E3%82%B7%E3%82%A7%E3%83%AB%E3%83%86%E3%82%A3%E3%83%BC%E5%88%A4%E5%AE%9Aai%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:24:23 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/machine_learning/%E3%82%B7%E3%82%A7%E3%83%AB%E3%83%86%E3%82%A3%E3%83%BC%E5%88%A4%E5%AE%9Aai%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B/</guid>
      <description>シェルティー判定 AI を作成する 謝辞 まず初めに参考にさせていただきました。 大変感謝申し上げます。
https://qiita.com/yottyann1221/items/a08300b572206075ee9f https://qiita.com/tomo_20180402/items/e8c55bdca648f4877188 https://qiita.com/mainvoidllll/items/db991dc30d3ddced6250 https://newtechnologylifestyle.net/keras_imagedatagenerator/
掲載している画像はフリー画像を使用させていただきました。 https://pixabay.com/ja/
序 機械学習に入門しました。 ざっとぐぐったところこんな感じで進めていくようです。
 大量の画像を用意する 教師／テストデータを作成する モデルを作成する モデルで評価する  今回は、画像認識でシェルティー判定プログラムを作成することにしました。
環境構築 Windows 10 に chocolatey で python3 を入れました。 venv で仮想環境を構築し、必要なライブラリを入れます。
&amp;gt; mkdir -p e:\python\ml &amp;gt; cd e:\python\ml &amp;gt; python -m venv ml &amp;gt; .\ml\Scripts\activate (ml)&amp;gt; pip install requests (ml)&amp;gt; pip install beautifulsoup4 # lxml を入れないと下のエラーが出る # bs4.FeatureNotFound: Couldn&amp;#39;t find a tree builder with the features you requested: lxml. Do you need to install a parser library?</description>
    </item>
    
    <item>
      <title>Pigで辞書を当てる</title>
      <link>https://mktkdyt.github.io/post/bigdata/pig%E3%81%A7%E8%BE%9E%E6%9B%B8%E3%82%92%E5%BD%93%E3%81%A6%E3%82%8B/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/pig%E3%81%A7%E8%BE%9E%E6%9B%B8%E3%82%92%E5%BD%93%E3%81%A6%E3%82%8B/</guid>
      <description>keywords.tsv
Hoge Fuga Piyo  辞書を読み込み，1行に変換する。  キーワードを OR で当てるため。    keywords_as_one_line = common_function.load_dictionary_as_one_line(&amp;#39;keywords.tsv&amp;#39;, &amp;#39;|&amp;#39;) def load_dictionary_as_one_line(dictionary_file, separator): with open(dictionary_file) as f: lines_one_str = &amp;#39;&amp;#39; # a\nb\nc\n -&amp;gt; a|b|c|d lines = f.readlines() for line in lines: word = line.rstrip(os.linesep) if(word != &amp;#39;&amp;#39;): lines_one_str += word + separator return lines_one_str[:-1]  本文に matches で辞書のキーワードが含まれるか見る。  Pig テンプレートに1行に変換したキーワードを埋め込む。    COND = { &amp;#39;$KEYWORDS&amp;#39;: f&amp;#39;.*({keywords_as_one_line}).*&amp;#39;, }_ common_function.translate_pig(&amp;#39;extract_text_template.pig&amp;#39;, &amp;#39;extract_text.pig&amp;#39;, COND) def translate_pig(template: str, output: str, d: {str, str}): for i, (k, v) in enumerate(d.</description>
    </item>
    
    <item>
      <title>Pig使い方まとめ</title>
      <link>https://mktkdyt.github.io/post/bigdata/pig%E4%BD%BF%E3%81%84%E6%96%B9%E3%81%BE%E3%81%A8%E3%82%81/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/pig%E4%BD%BF%E3%81%84%E6%96%B9%E3%81%BE%E3%81%A8%E3%82%81/</guid>
      <description>テキスト処理 改行除く  ^M（CR）も除く。  REPLACE(REPLACE(REPLACE(REPLACE(text, &amp;#39;\\t&amp;#39;, &amp;#39;&amp;#39;), &amp;#39;\\r\\n&amp;#39;, &amp;#39;&amp;#39;), &amp;#39;\\n&amp;#39;, &amp;#39;&amp;#39;), &amp;#39;\\\\^M&amp;#39;, &amp;#39;&amp;#39;) CONCAT  文字列を結合する。  CONCAT(&amp;#39;https://sample.jp?user=&amp;#39;, user) 条件演算 INDEXOF  指定した文字列がカラムに含まれているかを見る。  -- text に「プレゼント」が含まれていないレコードを抽出する FILTERED = FILTER DATA BY INDEXOF(text, &amp;#39;プレゼント&amp;#39;) &amp;lt; 0 -- text に「ビッグデータ」が含まれているレコードを抽出する FILTERED = FILTER DATA BY INDEXOF(text, &amp;#39;ビッグデータ&amp;#39;) &amp;gt; 0 日時フィルター  ToDate() で文字列を日時に変換可能。  -- 2019-05-31 00:00:00 から 2019-06-01 00:00:00 に登録されたユーザを抽出する FILTERED_USER = FILTER USER BY ToDate(&amp;#39;2019-05-31 00:00:00&amp;#39;,&amp;#39;yyyy-MM-dd HH:mm:ss&amp;#39;) &amp;lt;= ToDate(created,&amp;#39;yyyy-MM-dd HH:mm:ss&amp;#39;) AND ToDate(created,&amp;#39;yyyy-MM-dd HH:mm:ss&amp;#39;) &amp;lt; ToDate(&amp;#39;2019-06-01 00:00:00&amp;#39;,&amp;#39;yyyy-MM-dd HH:mm:ss&amp;#39;); 関係演算 ユニークを取る -- 重複を除く UNIQ_USER = DISTINCT USER; 取得件数を制限する -- 5 件に制限する L = LIMIT DATA 5; 集合演算 内部結合する USER1 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); USER2 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); J = JOIN USER1 BY id, USER2 BY id; 外部結合する USER1 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); USER2 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); J = JOIN USER1 BY id LEFT OUTER, USER2 BY id; 差集合を取る  JOIN して片方の Relation が NULL なレコードを抽出する。  USER1 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); USER2 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); J = JOIN USER1 BY id LEFT OUTER, USER2 BY id; USER1_MINUS_USER2 = FILTER J BY USER2::id is NULL; 積集合を取る  JOIN して片方の Relation が not NULL なレコードを抽出する。  USER1 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); USER2 = LOAD &amp;#39;/tmp/user1&amp;#39; USING PigStorage(&amp;#39;\\t&amp;#39;) AS (id:chararray); J = JOIN USER1 BY id LEFT OUTER, USER2 BY id; USER1_AND_USER2 = FILTER J BY USER2::id is not NULL; 出力 TSV 出力 FS -rm -r -f -skipTrash /tmp/some_dir/ STORE DATA INTO &amp;#39;/tmp/some_dir&amp;#39; USING PigStorage(&amp;#39;\t&amp;#39;);  -schema オプションを付与することで load するときにカラム名と型を指定しなくてよくなる。  FS -rm -r -f -skipTrash /tmp/some_dir/ STORE DATA INTO &amp;#39;/tmp/some_dir&amp;#39; USING PigStorage(&amp;#39;\t&amp;#39;, &amp;#39;-schema&amp;#39;); ORC 出力  データ量を削減したい場合に使用する。  FS -rm -r -f -skipTrash /tmp/some_dir/ STORE DATA INTO &amp;#39;/tmp/some_dir&amp;#39; USING OrcStorage(&amp;#39;-c ZLIB&amp;#39;); Pig 実行 コマンド実行  Pig ファイルを指定し pig コマンドを実行する。  pig test.</description>
    </item>
    
    <item>
      <title>ビッグデータ分析で使用するPythonコード一覧</title>
      <link>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%A7%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8Bpython%E3%82%B3%E3%83%BC%E3%83%89%E4%B8%80%E8%A6%A7/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%A7%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8Bpython%E3%82%B3%E3%83%BC%E3%83%89%E4%B8%80%E8%A6%A7/</guid>
      <description>環境構築  必要に応じて仮想環境を作る。  仮想環境作成 $ python3 -m venv test 仮想環境有効化 $ source test/bin/activate (test)$ 仮想環境無効化 (test)$ deactivate $ 文字列処理 文字列を切り出す  [開始インデックス:終了文字番号(インデックスではないことに注意)]とする。  s = &amp;#34;2019-06-01&amp;#34; print(f&amp;#34;{s[0:4]}-{s[5:7]}-{s[8:10]}&amp;#34;) エスケープ 波括弧のエスケープ  波括弧は波括弧でエスケープする。  var = &amp;#39;aiuto&amp;#39; print( f&amp;#34;val is {{{var}}}&amp;#34; ) ディレクトリ操作 ディレクトリ作成 import os os.makidirs(&amp;#39;tmp&amp;#39;, exist_ok=True) class  プロパティ等を別ファイルにしたい場合等に使用する。  classsample ├── main.py └── prop └── user_property.py main.py
from prop.user_property import UserProperty user_property = UserProperty({&amp;#39;first_name&amp;#39;: &amp;#39;イチロー&amp;#39;, &amp;#39;family_name&amp;#39;: &amp;#39;テスト&amp;#39;}) print(f&amp;#39;{user_property.FAMILY_NAME} {user_property.</description>
    </item>
    
    <item>
      <title>ビッグデータ分析で使用するシェルコマンド一覧</title>
      <link>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%A7%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8B%E3%82%B7%E3%82%A7%E3%83%AB%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E4%B8%80%E8%A6%A7/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%A7%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8B%E3%82%B7%E3%82%A7%E3%83%AB%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E4%B8%80%E8%A6%A7/</guid>
      <description>ビッグデータ分析で使用してきたシェルコマンドをまとめた。
ターミナル表示 echo で文字列エスケープ $ echo &amp;#34;\&amp;#34;&amp;#34; &amp;#34; echo で改行表示  -e で改行を表示出来る。  $ txt=&amp;#34;a\nb\nc&amp;#34; $ echo -e &amp;#34;$txt&amp;#34; a b c テキスト処理 文字列から offset を指定して抽出する  日付文字列から年月日を抽出する際に使用する。  $ d=&amp;#34;20190630&amp;#34; $ echo ${d:0:4} 2019 $ echo ${d:4:2} 06 文字列の長さを取得する $ txt=&amp;#34;abcdef&amp;#34; $ echo ${#txt} 6 ファイル処理 tsvから特定の列を抽出する  cut コマンドで取り出せる。 ただし，複数列取り出せても順番を入れ替えることは出来ない。  $ cat test.tsv | cut -f3,4  awk でも可能。 awk だと列を入れ替えることができる。 -F で区切り文字を指定する  $ awk -F&amp;#39;\t&amp;#39; &amp;#39;{print $4 &amp;#34;\t&amp;#34; $3}&amp;#39; -f test.</description>
    </item>
    
    <item>
      <title>ビッグデータ分析のエラーハンドリング</title>
      <link>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%8F%E3%83%B3%E3%83%89%E3%83%AA%E3%83%B3%E3%82%B0/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%8F%E3%83%B3%E3%83%89%E3%83%AA%E3%83%B3%E3%82%B0/</guid>
      <description>リトライ時の処理スキップ  Pig 実行前に Pig の成果物が既に HDFS に存在するか確認し存在する場合は処理をスキップするようにした。 強制実行オプションを設け，指定された場合は成果物が既にある処理も実行されるようにした。  # 強制実行オプション @click.option( &amp;#39;--force&amp;#39;, &amp;#39;-f&amp;#39;, &amp;#39;force&amp;#39;, is_flag=True, help=&amp;#39;強制実行フラグ。これを立てたら既に抽出済みの処理も再実行する。&amp;#39; ) def exists_in_hdfs(hdfs_path: str) -&amp;gt; bool: &amp;#34;&amp;#34;&amp;#34;HDFS上のパスに指定したディレクトリ・ファイルが存在しているか否かを返す Arguments: hdfs_path {str} -- HDFS上のパス Returns: bool -- 存在していればTrue, していなければFalse &amp;#34;&amp;#34;&amp;#34; result = subprocess.run([&amp;#34;hadoop&amp;#34;, &amp;#34;fs&amp;#34;, &amp;#34;-test&amp;#34;, &amp;#34;-e&amp;#34;, hdfs_path]) if result.returncode == 0: return True else: return False def exists_all_in_hdfs(src_list) -&amp;gt; bool: &amp;#34;&amp;#34;&amp;#34;リストで指定したディレクトリ・ファイルが全て HDFS に存在するかを検証します。 Arguments: src_tupple -- HDFS のパス Returns: bool -- 全て存在すれば True，それ以外の場合は False &amp;#34;&amp;#34;&amp;#34; for src in src_list: if(not exists_in_hdfs(src)): logger.</description>
    </item>
    
    <item>
      <title>外部 API 並列処理</title>
      <link>https://mktkdyt.github.io/post/bigdata/%E5%A4%96%E9%83%A8api%E4%B8%A6%E5%88%97%E5%87%A6%E7%90%86/</link>
      <pubDate>Thu, 14 Jan 2021 17:23:48 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/%E5%A4%96%E9%83%A8api%E4%B8%A6%E5%88%97%E5%87%A6%E7%90%86/</guid>
      <description>HDFS から対象のIDを取り出す。  uniq で重複排除する。   標準入力を split で n 分割する。  行数にデータ件数の 1/n を指定することで標準入力を n 分割する。 分割されたファイルは tmp/000* の形式で出力される（分割したらファイル出力されてしまう）。    split_cnt = 10 text_hdfs_dir = &amp;#39;/text&amp;#39; tmp_dir = &amp;#39;tmp&amp;#39; c = f&amp;#39;hadoop fs -cat \&amp;#39;{text_hdfs_dir}/part-*\&amp;#39;| cut -f1 | grep -E \&amp;#39;^[0-9]{{1,30}}$\&amp;#39;| sort | uniq | split -l $(($(hadoop fs -cat \&amp;#39;{text_hdfs_dir}/part-*\&amp;#39;| cut -f1 | grep -E \&amp;#39;^[0-9]{{1,30}}$\&amp;#39;| sort | uniq | wc -l)/{split_cnt}+1)) -d -a 5 - {tmp_dir}/&amp;#39; subprocess.</description>
    </item>
    
    <item>
      <title>Hadoopコマンドまとめ</title>
      <link>https://mktkdyt.github.io/post/bigdata/hadoop%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%BE%E3%81%A8%E3%82%81/</link>
      <pubDate>Thu, 14 Jan 2021 17:22:56 +0900</pubDate>
      
      <guid>https://mktkdyt.github.io/post/bigdata/hadoop%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%BE%E3%81%A8%E3%82%81/</guid>
      <description>Hadoop コマンドまとめ ジョブ関連 Hadoop のジョブを一覧表示する $ yarn application -list Hadoop のジョブを強制終了する $ yarn application -kill $application_id queue を変更する $ yarn application -movetoqueue $application_id -queue $queue_name HDFS ディレクトリ操作 HDFS のディレクトリの中身を確認する $ hadoop fs -ls /tmp/some_dir HDFS のディレクトリを削除する $ hadoop fs -rm -r /tmp/some_dir HDFS にディレクトリを作成する $ hadoop fs -mkdir /tmp/some_dir HDFS ファイル操作 HDFS にローカルのファイルを置く $ hadoop fs -put /home/user/some.tsv /tmp/some_dir/rawdata.tsv HDFS の中身を表示する $ hadoop fs -cat /tmp/some_dir/rawdata.tsv HDFS の中身をローカルに吐き出す HDFS に TSV で格納した場合。</description>
    </item>
    
  </channel>
</rss>
